{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBA5IPyb4BFH"
   },
   "source": [
    "# –ï–≥–æ –≤–µ–ª–∏—á–µ—Å—Ç–≤–æ, \"–¥–æ–º–∞—à–∫–∞ ‚Ññ1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOnY6pwvpghE"
   },
   "source": [
    "–í —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç–µ –≤–∞–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—É—á–∏—Ç—å Byte-level BPE —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –Ω–µ–±–æ–ª—å—à—É—é LM.  \n",
    "\n",
    "–î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤: —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Transformer –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ —Å —Ä—É—Å—Å–∫–∏–º–∏ –∞–Ω–µ–∫–¥–æ—Ç–∞–º–∏!\n",
    "\n",
    "–û–±—É—á–µ–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å –º–æ–∂–Ω–æ –∏ –Ω—É–∂–Ω–æ –≤—ã–ª–æ–∂–∏—Ç—å –Ω–∞ [ü§ó HuggingFace](https://huggingface.co/). –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å —Ç–∞–º, –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ [deep vk](https://huggingface.co/deepvk) –∏ —Å–æ–∑–¥–∞–π—Ç–µ —Å–µ–±–µ API —Ç–æ–∫–µ–Ω.\n",
    "\n",
    "–°–ª–µ–¥—É–π—Ç–µ —è—á–µ–π–∫–∞–º —Ç–µ—Ç—Ä–∞–¥–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–π—Ç–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏. –í –∫–æ–Ω—Ü–µ —Ç–µ—Ç—Ä–∞–¥–∫–∏ –≤—ã –Ω–∞–π–¥–µ—Ç–µ –∑–∞–¥–∞—á–∏ —Å–æ –∑–≤–µ–∑–¥–æ—á–∫–æ–π, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T18:06:57.842071Z",
     "iopub.status.busy": "2025-03-15T18:06:57.840584Z",
     "iopub.status.idle": "2025-03-15T18:07:03.393272Z",
     "shell.execute_reply": "2025-03-15T18:07:03.391969Z",
     "shell.execute_reply.started": "2025-03-15T18:06:57.842016Z"
    },
    "id": "0byNYx5dzB4b",
    "outputId": "551e98bc-160f-4783-d35c-9b036497a66f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "\n",
    "%pip install --quiet datasets livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T19:48:42.394676Z",
     "iopub.status.busy": "2025-03-15T19:48:42.393520Z",
     "iopub.status.idle": "2025-03-15T19:48:42.409989Z",
     "shell.execute_reply": "2025-03-15T19:48:42.408740Z",
     "shell.execute_reply.started": "2025-03-15T19:48:42.394638Z"
    },
    "id": "UILR1tu3z9oI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã\n",
    "\n",
    "import inspect\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from functools import lru_cache, partial\n",
    "from pathlib import Path\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi, PyTorchModelHubMixin, interpreter_login, snapshot_download\n",
    "from huggingface_hub.utils import SoftTemporaryDirectory\n",
    "from livelossplot import PlotLosses\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:07:11.017516Z",
     "iopub.status.busy": "2025-03-15T18:07:11.016144Z",
     "iopub.status.idle": "2025-03-15T18:07:11.033513Z",
     "shell.execute_reply": "2025-03-15T18:07:11.032227Z",
     "shell.execute_reply.started": "2025-03-15T18:07:11.017459Z"
    },
    "id": "4p7OLSivnPW0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –≠—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –±—É–¥—É—Ç –ø–æ–º–µ—á–µ–Ω—ã –≤—Å–µ –º–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å\n",
    "# –≠—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ —Ü–µ–ª—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç–∞–∫ –∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö\n",
    "# –í—Å–µ–≥–¥–∞ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–Ω—Ç—Ä–æ—Å–ø–µ–∫—Ü–∏–µ–π –∏ –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ :)\n",
    "\n",
    "\n",
    "def todo():\n",
    "    stack = inspect.stack()\n",
    "    caller_frame = stack[1]\n",
    "    function_name = caller_frame.function\n",
    "    line_number = caller_frame.lineno\n",
    "    raise NotImplementedError(f\"TODO at {function_name}, line {line_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T18:07:11.035584Z",
     "iopub.status.busy": "2025-03-15T18:07:11.034878Z",
     "iopub.status.idle": "2025-03-15T18:07:28.352840Z",
     "shell.execute_reply": "2025-03-15T18:07:28.351660Z",
     "shell.execute_reply.started": "2025-03-15T18:07:11.035532Z"
    },
    "id": "bCkJJp2JK99x",
    "outputId": "8a2c5f73-cbc5-44f2-c147-417e795041f8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "Add token as git credential? (Y/n)  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-03-15T18:07:54.621214Z",
     "iopub.status.idle": "2025-03-15T18:07:54.621799Z",
     "shell.execute_reply": "2025-03-15T18:07:54.621546Z",
     "shell.execute_reply.started": "2025-03-15T18:07:54.621521Z"
    },
    "id": "GVWKkwaryDTq",
    "outputId": "83d82bc5-fde4-4949-ae5e-7e65be2d7ac9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –±—É–¥—É—â–µ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "username = HfApi().whoami()[\"name\"]\n",
    "REPO_NAME = f\"{username}/llm-course-hw1\"  # –ò–ª–∏ –∫–∞–∫ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è\n",
    "\n",
    "print(f\"Homework repository: '{REPO_NAME}'\")\n",
    "\n",
    "# –ò –¥—Ä—É–≥–∏–µ –ø–æ–ª–µ–∑–Ω—ã–µ –≤–µ—â–∏\n",
    "SEED = 0xC0FFEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxN5JUbZ3ToV"
   },
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç\n",
    "\n",
    "–ü–µ—Ä–≤—ã–º –¥–µ–ª–æ–º –∑–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ: [ü§ó IgorVolochay/russian_jokes](https://huggingface.co/datasets/IgorVolochay/russian_jokes)\n",
    "\n",
    "–ò –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–∏—Ö üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "e18aaaff13e34718a78e002f9885df74",
      "14c8108aeb4948a6a4ba3550ea9d37bf",
      "3d557e71f38243ebb6c85fb3e047e84e",
      "fce9a87690fe4561a53b054c79e43d53",
      "956b26d084924d2582574db2be8d97c0",
      "c9abe5664d2d419cbcecd38c715d9922",
      "6ae4774b8711429eb28df01f421cfb0c",
      "1f62151ca61c4a5c87eeb5bb9aaf81de",
      "576096f3007944df9d4ff5af3d6c413d",
      "5c9b1715d728425abe95eebc527b7176",
      "9f33ccba758e49d3a7c31c29d34701a6",
      "ca6256d7781343ffa87c7a727818b48b",
      "7eea9472943a4a46aea249ac2d34add6",
      "3337363073324d59930d930e2bb9a4ed",
      "e211fd35db594830a66d0aeaf78eeb98",
      "eca658866bac4dab9a92b5d18bd5a93b",
      "fd13ac6e0154498390a04783992ca005",
      "2f37e138d5a4415b995eb782821e852b",
      "8183376e49a1468695840a2c28e1c2e8",
      "5f3ae8e54b88464085c79265f3f1cbe6",
      "9283be55fa9748458f7beccfb709dd8e",
      "8ee13c0245bb4bbe9322eae6765e9cad",
      "bb14a1a17c044c6d99331047b1072c55",
      "ae9bed8b24c94d3688321ced271545d3",
      "f8b0945c30b04470b16227e9c470d135",
      "f4e211125114450b8000ed793d25cf5f",
      "053e185c1b06448797d09b5e87e9639a",
      "ae91c80126594ce485b022d87bc6f9f9",
      "b0e15a7eb24b430fb6d42fc10b6c8ebe",
      "f93543a7b33a42339b37b9cbab78b330",
      "5430ae92129342f19d5fceed4f0e3eb3",
      "d2d3a80f70474cbdb516a373f06bf9a3",
      "fed46355edb84e45834d4d9906817770"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T18:07:28.751426Z",
     "iopub.status.busy": "2025-03-15T18:07:28.750041Z",
     "iopub.status.idle": "2025-03-15T18:07:36.902007Z",
     "shell.execute_reply": "2025-03-15T18:07:36.900794Z",
     "shell.execute_reply.started": "2025-03-15T18:07:28.751389Z"
    },
    "id": "rT78JNcqpRXW",
    "outputId": "6ff56cce-e1e4-4b30-d906-32ce48c5384d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- –ó—è—Ç—å, –∞ —Ç—ã –∑–Ω–∞–µ—à—å, –≥–¥–µ –Ω–∞–π—Ç–∏ —Ç–æ–≥–æ –º—É–∂—á–∏–Ω—É, –∫–æ—Ç–æ—Ä—ã–π —Å–ø–∞—Å –º–µ–Ω—è, –∫–æ–≥–¥–∞ —è —Ç–æ–Ω—É–ª–∞?- –î–∞, –æ–Ω —É–∂–µ –ø—Ä–∏—Ö–æ–¥–∏–ª –∫–æ –º–Ω–µ –∏–∑–≤–∏–Ω—è—Ç—å—Å—è!\n",
      "===\n",
      "–ü–æ—Å–ª–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∞–∫—Ü–∏–∏ \"–ö –∂–∏–≤–æ—Ç–Ω—ã–º –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏\" –∂–∏–≤–æ—Ç–Ω—ã–µ –ø–æ—Å–æ–≤–µ—â–∞–ª–∏—Å—å –∏ —Ä–µ—à–∏–ª–∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞–∫—Ü–∏—é \"–ö —á–µ–ª–æ–≤–µ–∫—É –ø–æ-—Å–∫–æ—Ç—Å–∫–∏\".\n",
      "===\n",
      "–®—Ç–∏—Ä–ª–∏—Ü –ø—Ä–∏—à–µ–ª –¥–æ–º–æ–π –∏ —Å—Ä–∞–∑—É –∑–∞–≤–∞–ª–∏–ª—Å—è –Ω–∞ –±–æ–∫–æ–≤—É—é. –°—Ä–µ–¥–Ω—è—è –æ—Ç –¥–æ—Å–∞–¥—ã –∑–∞–ø–ª–∞–∫–∞–ª–∞.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"IgorVolochay/russian_jokes\")\n",
    "print(\"\\n===\\n\".join(dataset[\"train\"][\"text\"][:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T18:07:36.904198Z",
     "iopub.status.busy": "2025-03-15T18:07:36.903537Z",
     "iopub.status.idle": "2025-03-15T18:07:36.980851Z",
     "shell.execute_reply": "2025-03-15T18:07:36.979734Z",
     "shell.execute_reply.started": "2025-03-15T18:07:36.904164Z"
    },
    "id": "z7G7o6OdK99z",
    "outputId": "4059033b-a3a0-47f3-f4a8-918d025e2bd7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 135497\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 15056\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ö–æ–ª–¥–∞—É—Ç—ã\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=SEED)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZzvdEVO3-kM"
   },
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä [6 –±–∞–ª–ª–æ–≤]\n",
    "\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç Byte-level BPE.\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ:\n",
    "1. –†–µ–∞–ª–∏–∑—É–µ–º –µ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏ –Ω–∞–±–æ—Ä —Å–ª–∏—è–Ω–∏–π –ø–æ —ç—Ç–æ–º—É —Å–ª–æ–≤–∞—Ä—é\n",
    "2. –û–±—É—á–∏–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "3. –†–µ–∞–ª–∏–∑—É–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-15T18:07:54.623576Z",
     "iopub.status.idle": "2025-03-15T18:07:54.624288Z",
     "shell.execute_reply": "2025-03-15T18:07:54.624016Z",
     "shell.execute_reply.started": "2025-03-15T18:07:54.623977Z"
    },
    "id": "15U6H1iLU3kI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –í—Å—è–∫–∏–µ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏\n",
    "\n",
    "WHITESPACE_SPLITTER = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
    "\n",
    "\n",
    "def bytes_to_unicode() -> dict[int, str]:\n",
    "    \"\"\"The original dictionary consists of 256 bytes and their corresponding Unicode characters.\n",
    "    For example, chr(33) is '!'. However, not all bytes have a visually appealing representation,\n",
    "    so such characters are skipped and replaced with the first available ones, i.e. shifted by 256.\n",
    "    \"\"\"\n",
    "    initial_bytes = (\n",
    "        list(range(ord(\"!\"), ord(\"~\") + 1)) + list(range(ord(\"¬°\"), ord(\"¬¨\") + 1)) + list(range(ord(\"¬Æ\"), ord(\"√ø\") + 1))\n",
    "    )\n",
    "    initial_chars = [chr(it) for it in initial_bytes]\n",
    "    n = 0\n",
    "    for byte in range(2**8):\n",
    "        if byte not in initial_bytes:\n",
    "            initial_bytes.append(byte)\n",
    "            initial_chars.append(chr(2**8 + n))\n",
    "            n += 1\n",
    "    return dict(sorted(zip(initial_bytes, initial_chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-15T18:07:54.626672Z",
     "iopub.status.idle": "2025-03-15T18:07:54.627303Z",
     "shell.execute_reply": "2025-03-15T18:07:54.627029Z",
     "shell.execute_reply.started": "2025-03-15T18:07:54.627003Z"
    },
    "id": "yk919hENEFwL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_word(word, id2token):\n",
    "    tokenized_word = []\n",
    "    for token in word:\n",
    "        byte_token = token.encode('utf-8')\n",
    "        token = ''\n",
    "        for value in byte_token:\n",
    "            token += id2token[value]\n",
    "        tokenized_word.append(token)\n",
    "    return tokenized_word\n",
    "\n",
    "def merge(merge_pair: tuple[str, str], pair_frequences: Counter[tuple[str, str]], words_by_tokens: Counter[tuple[str]]):\n",
    "    \"\"\"Merges a given pair of tokens and update corresponding stats\n",
    "\n",
    "    Args:\n",
    "        merge_pair: The pair of tokens to be merged.\n",
    "        pair_frequences: A counter tracking the frequency of token pairs in the dataset.\n",
    "        words_by_tokens: A counter mapping tokenized words to their frequencies.\n",
    "\n",
    "    Returns:\n",
    "        Updated pair frequences and word tokenization w.r.t. to new token.\n",
    "    \"\"\"\n",
    "    if merge_pair[1] == '':\n",
    "        return pair_frequences, words_by_tokens\n",
    "    deleted_words = {}\n",
    "    pair = merge_pair[0] + merge_pair[1]\n",
    "    for word in words_by_tokens:\n",
    "        starts = []\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i] == merge_pair[0] and word[i+1] == merge_pair[1]:\n",
    "                starts.append(i)\n",
    "        for start in starts:\n",
    "            if start >= 1:\n",
    "                pair_frequences[(word[start-1], merge_pair[0])] -= words_by_tokens[word]\n",
    "                pair_frequences[(word[start-1], pair)] += words_by_tokens[word]\n",
    "            if start < len(word)-2:\n",
    "                pair_frequences[(merge_pair[1], word[start+2])] -= words_by_tokens[word]\n",
    "                pair_frequences[(pair, word[start+2])] += words_by_tokens[word]\n",
    "\n",
    "        word_new = []\n",
    "        prev_start = 0\n",
    "        for start in starts:\n",
    "            word_new += word[prev_start:start]\n",
    "            word_new += [word[start] + word[start+1]]\n",
    "            prev_start = start\n",
    "        word_new += word[prev_start+2:]\n",
    "        if starts:\n",
    "            deleted_words[word] = tuple(word_new)\n",
    "    for word in deleted_words:\n",
    "        words_by_tokens[deleted_words[word]] = words_by_tokens[word]\n",
    "        del words_by_tokens[word]\n",
    "    return pair_frequences, words_by_tokens\n",
    "\n",
    "def train(data: list[str], vocab_size: int = 1024, special_tokens: list[str] = None):\n",
    "    \"\"\"Train BPE tokenizer on passed data\n",
    "\n",
    "    Args:\n",
    "        data: List of train documents\n",
    "        vocab_size: Size of target vocabulary\n",
    "        special_tokens: List of special tokens to add into vocabulary\n",
    "    Returns:\n",
    "        vocabulary: mapping from string token to id\n",
    "        merges: list of merges, each one is tuple of string tokens\n",
    "    \"\"\"\n",
    "    if vocab_size < 256:\n",
    "        raise ValueError(\"Vocab size can't be less than 256\")\n",
    "    if special_tokens is None:\n",
    "        special_tokens = []\n",
    "\n",
    "    # 1. Initialize vocabulary (using inverse one during training)\n",
    "    id2token = bytes_to_unicode()\n",
    "    merges = []\n",
    "    # 2. Load data\n",
    "    solo_tokens = Counter()\n",
    "    words_by_tokens = Counter()\n",
    "    for sample in tqdm(data, desc=\"Loading data\"):\n",
    "        # 2.1 Split into words\n",
    "        words = WHITESPACE_SPLITTER.findall(sample.strip())\n",
    "        for word in words:\n",
    "            # 2.2 Tokenize with base vocabulary\n",
    "            tokenized_word = tokenize_word(word, id2token)\n",
    "            words_by_tokens.update([tuple(tokenized_word)])\n",
    "            solo_tokens.update(tokenized_word)\n",
    "    # 3. Calculate statistic of token's pairs\n",
    "    pair_frequences = Counter()\n",
    "    for word in words_by_tokens:\n",
    "        for index in range(len(word) - 1):\n",
    "            pair_frequences[(word[index], word[index+1])] += words_by_tokens[word]\n",
    "    for token in solo_tokens:\n",
    "        pair_frequences[(token, '')] = solo_tokens[token]\n",
    "    # 4. Build vocabulary\n",
    "    pbar = trange(vocab_size, desc=\"Building vocabulary\", initial=len(id2token) + len(special_tokens))\n",
    "    while len(id2token) < vocab_size - len(special_tokens):\n",
    "        if len(pair_frequences) == 0:\n",
    "            print(\"Not enough data to fulfil vocabulary\")\n",
    "            break\n",
    "\n",
    "        # 4.1 Find the most frequent pair and create new token\n",
    "        top_pair = pair_frequences.most_common(1)[0][0]\n",
    "        new_token = top_pair[0] + top_pair[1]\n",
    "        del pair_frequences[top_pair]\n",
    "\n",
    "        # 4.2 Add to vocabulary\n",
    "        if new_token in id2token.values():\n",
    "            continue\n",
    "        id2token[len(id2token)] = new_token\n",
    "        merges.append(top_pair)\n",
    "\n",
    "        # 4.3 Update stats and merge the top pair in all tokens\n",
    "        pair_frequences, words_by_tokens = merge(top_pair, pair_frequences, words_by_tokens)\n",
    "\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "    # 5. Add special tokens\n",
    "    for special_token in special_tokens:\n",
    "        id2token[len(id2token)] = special_token\n",
    "\n",
    "    return {v: k for k, v in id2token.items()}, merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "4e8103f6f1d348348cb3d0ead13c08a0",
      "037240195ea648ea977cbeddb6802e3c",
      "0ad00686d85046af8b16caef0031c463",
      "ed9c593acfca4464875afefb495b0504",
      "7510595287c1413a95cbfade6c892a6b",
      "4263d7a2a60640868b212423ad19460a",
      "17cd05a39e2f424ab2ab1e1b99563ed0",
      "b92761d040a74ade8ba4472cdad0d8c9",
      "ad9ab0253a824e45b373b5756b5062f0",
      "89e4f0d4d779403a96da3b69fd541e8c",
      "d983d2e8ac7944a58434df7c4535b019",
      "dce0fdb966f64c629c8e7ede50fe0207",
      "c86beee2cbbf4f949f9e02ababbe58ff",
      "0e47a520ae554b42b2f1915aae431567",
      "019ec19c587a4e7994f85c8454fe613f",
      "25a6a07d0c2042b49faa8e9b90e9b520",
      "d0c6421149b641ef892e3c99d85b2727",
      "f2cf249ff0db4a70a67e6ef9ce37da02",
      "4f958e47bb7c4dc28dab57743021b06b",
      "a2488b690c3947e9908968970903afba",
      "8c72de7e16ef44818bb66330fc549ef5",
      "5cb623ff47ac43449f52fc327ebac6cb"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T18:08:01.855699Z",
     "iopub.status.busy": "2025-03-15T18:08:01.854291Z",
     "iopub.status.idle": "2025-03-15T18:08:01.884230Z",
     "shell.execute_reply": "2025-03-15T18:08:01.882975Z",
     "shell.execute_reply.started": "2025-03-15T18:08:01.855645Z"
    },
    "id": "iLwur-KgK990",
    "outputId": "ac73c089-160a-4e64-a54d-4bc844c1ed87",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –û–±—É—á–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö\n",
    "# –î–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏ —Ö–≤–∞—Ç–∏—Ç –∏ –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è, –Ω–æ –º–æ–∂–µ—Ç–µ –ø—Ä–æ–±–æ–≤–∞—Ç—å –∏ –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –æ–±—É—á–∏—Ç—å!\n",
    "\n",
    "# vocab, merges = train(dataset[\"train\"][\"text\"], vocab_size=1024, special_tokens=[\"[EOS]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T18:08:02.152744Z",
     "iopub.status.busy": "2025-03-15T18:08:02.151251Z",
     "iopub.status.idle": "2025-03-15T18:08:02.195808Z",
     "shell.execute_reply": "2025-03-15T18:08:02.194260Z",
     "shell.execute_reply.started": "2025-03-15T18:08:02.152690Z"
    },
    "id": "kcsapJUAK990",
    "outputId": "11302f2a-285a-40dc-fe71-b42e8b0d9cae",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8117/575341787.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0municode_to_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbytes_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mraw_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0municode_to_bytes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Token #{token_id}: '{raw_bytes.decode('utf-8', errors='replace')}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã\n",
    "\n",
    "# random_tokens = [512, 614, 768, 888, 1022]\n",
    "# unicode_to_bytes = {v: k for k, v in bytes_to_unicode().items()}\n",
    "# for token_id in random_tokens:\n",
    "#     token = [k for k, v in vocab.items() if v == token_id][0]\n",
    "#     raw_bytes = bytes([unicode_to_bytes[it] for it in token])\n",
    "#     print(f\"Token #{token_id}: '{raw_bytes.decode('utf-8', errors='replace')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T20:06:20.712798Z",
     "iopub.status.busy": "2025-03-15T20:06:20.711515Z",
     "iopub.status.idle": "2025-03-15T20:06:20.744978Z",
     "shell.execute_reply": "2025-03-15T20:06:20.743802Z",
     "shell.execute_reply.started": "2025-03-15T20:06:20.712756Z"
    },
    "id": "ugUz7cma1Czs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ByteLevelBPETokenizer:\n",
    "\n",
    "    def __init__(self, vocab: dict[str, int], merges: list[tuple[str, str]], eos_token: str = \"[EOS]\"):\n",
    "        \"\"\"Byte-Level BPE Tokenizer\n",
    "\n",
    "        Args:\n",
    "            vocab: mapping from string token to id\n",
    "            merges: list of merges in prioritized order\n",
    "            eos_token: string representation of EOS token\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if eos_token not in vocab:\n",
    "            raise ValueError(\"There is no EOS token in vocab\")\n",
    "        self.byte_encoder = bytes_to_unicode()\n",
    "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
    "        self.token2id = vocab\n",
    "        self.id2token = {v: k for k, v in self.token2id.items()}\n",
    "        self.eos_token = eos_token\n",
    "        self.eos_token_id = self.token2id[eos_token]\n",
    "\n",
    "        # The closer the pair is to the beginning, the higher the rank\n",
    "        self.merges = merges\n",
    "        self.bpe_ranks = {pair: i for i, pair in enumerate(merges)}\n",
    "\n",
    "    @lru_cache\n",
    "    def bpe(self, word: tuple[str]) -> tuple[str]:\n",
    "        \"\"\"Process word into tokenized representation.\n",
    "        Word is a tuple of base tokens, i.e. bytes.\n",
    "\n",
    "        Under the hood:\n",
    "        1. Tracks the set of token pairs, bi-grams\n",
    "        2. While possible, replaces the highest-ranking pair with its union\n",
    "\n",
    "        Args:\n",
    "            word: list of base string tokens\n",
    "        Return:\n",
    "            list of BPE tokens\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            rank = float('inf')\n",
    "            index = -1\n",
    "            for i in range(len(word) - 1):\n",
    "                if (word[i], word[i+1]) in self.bpe_ranks:\n",
    "                    if self.bpe_ranks[(word[i], word[i+1])] < rank:\n",
    "                        rank = self.bpe_ranks[(word[i], word[i+1])]\n",
    "                        index = i\n",
    "            if index == -1:\n",
    "                break\n",
    "            word = word[:index] + tuple([word[index] + word[index+1]]) + word[index+2:]\n",
    "        return word\n",
    "\n",
    "    def encode(self, text: str, add_eos_token: bool = True) -> list[int]:\n",
    "        \"\"\"Convert string to list of token ids.\n",
    "\n",
    "        Args:\n",
    "            text: input string, may contain multiple words\n",
    "            add_eos_token: whether to add eos token id at the end\n",
    "        Return:\n",
    "            list of ints, ids of tokenized text\n",
    "        \"\"\"\n",
    "        words = WHITESPACE_SPLITTER.findall(text)\n",
    "        tokens = []\n",
    "        for word in words:\n",
    "            tokenized_word = tokenize_word(word, self.id2token)\n",
    "            bpe_res = self.bpe(tuple(tokenized_word))\n",
    "            tokens += [self.token2id[token] for token in bpe_res if token in self.token2id]\n",
    "        if add_eos_token:\n",
    "            tokens += [self.token2id[self.eos_token]]\n",
    "        return tokens\n",
    "    def decode(self, idx: list[int]) -> str:\n",
    "        \"\"\"Convert list of tokens' ids to text, opposite to encode method\n",
    "\n",
    "        Args:\n",
    "            idx: list of tokens' ids\n",
    "        Return:\n",
    "            string, decoded text\n",
    "        \"\"\"\n",
    "        string = ''\n",
    "        for i in idx:\n",
    "            byte = [self.byte_decoder[tok] for tok in self.id2token[i]]\n",
    "            string += bytes(byte).decode('utf-8')\n",
    "            print(string)\n",
    "        return string\n",
    "\n",
    "    def push_to_hub(self, repo_id, *, private=None, token=None):\n",
    "        api = HfApi()\n",
    "        repo_id = api.create_repo(repo_id=repo_id, token=token, private=private, exist_ok=True).repo_id\n",
    "\n",
    "        # Push the files to the repo in a single commit\n",
    "        with SoftTemporaryDirectory() as tmp:\n",
    "            save_directory = Path(tmp) / repo_id\n",
    "            save_directory.mkdir(parents=True)\n",
    "            with open(save_directory / \"vocabulary.json\", \"w\") as f_out:\n",
    "                print(json.dumps(self.token2id, indent=2), file=f_out)\n",
    "            with open(save_directory / \"merges.json\", \"w\") as f_out:\n",
    "                print(json.dumps({\"merges\": self.merges}), file=f_out)\n",
    "\n",
    "            return api.upload_folder(repo_id=repo_id, folder_path=save_directory, token=token, commit_message='new_tokenizer')\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *, token=None, **model_kwargs):\n",
    "        if not os.path.isdir(pretrained_model_name_or_path):\n",
    "            storage_folder = snapshot_download(repo_id=pretrained_model_name_or_path, token=token)\n",
    "        else:\n",
    "            storage_folder = pretrained_model_name_or_path\n",
    "        storage_folder = Path(storage_folder)\n",
    "        with open(storage_folder / \"vocabulary.json\", \"r\") as f_in:\n",
    "            vocab = json.load(f_in)\n",
    "        with open(storage_folder / \"merges.json\", \"r\") as f_in:\n",
    "            merges = [tuple(it) for it in json.load(f_in)[\"merges\"]]\n",
    "        return cls(vocab, merges, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:08:09.998328Z",
     "iopub.status.busy": "2025-03-15T18:08:09.996852Z",
     "iopub.status.idle": "2025-03-15T18:08:10.016818Z",
     "shell.execute_reply": "2025-03-15T18:08:10.015648Z",
     "shell.execute_reply.started": "2025-03-15T18:08:09.998272Z"
    },
    "id": "xRTQzO3wK991",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
    "\n",
    "# tokenizer = ByteLevelBPETokenizer(vocab, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:08:10.143668Z",
     "iopub.status.busy": "2025-03-15T18:08:10.142329Z",
     "iopub.status.idle": "2025-03-15T18:08:10.157689Z",
     "shell.execute_reply": "2025-03-15T18:08:10.156458Z",
     "shell.execute_reply.started": "2025-03-15T18:08:10.143624Z"
    },
    "id": "-9m_65vBK991",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–∞ —Ö–∞–±\n",
    "\n",
    "# tokenizer.push_to_hub(REPO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T20:06:29.536757Z",
     "iopub.status.busy": "2025-03-15T20:06:29.535774Z",
     "iopub.status.idle": "2025-03-15T20:06:30.340578Z",
     "shell.execute_reply": "2025-03-15T20:06:30.339313Z",
     "shell.execute_reply.started": "2025-03-15T20:06:29.536721Z"
    },
    "id": "S9VohtKrK991",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  9.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# –°–∫–∞—á–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å —Ö–∞–±–∞\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer.from_pretrained(REPO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFvf_Q8knPW4",
    "outputId": "1bbccbae-7181-4966-f3ae-73a3d10be19b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞–±–æ—Ç—É —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "\n",
    "text = \"–ß—Ç–æ –±—ã–ª–æ –ø–æ–ª–≥–æ–¥–∞ –Ω–∞–∑–∞–¥? –ü–æ–º–∏–º–æ –≥—Ä–∞–Ω–¥–∏–æ–∑–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π, –ø–æ–ª–≥–æ–¥–∞ –Ω–∞–∑–∞–¥ –±—ã–ª–∏ –µ—â—ë —Å–µ–º–∏–Ω–∞—Ä—ã –ø–æ –ª–∏–Ω–µ–π–Ω–æ–π –∞–ª–≥–µ–±—Ä–µ.\"\n",
    "ids = tokenizer.encode(text)\n",
    "reverse_text = [tokenizer.decode([it]) for it in ids]\n",
    "print(\"|\".join(reverse_text))\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "0cf300f7cab7420e86f57e862008c1f9",
      "8bef2bdc77c9495485eba1b25b8c1ea7",
      "f0543bf2eda2481dbb19fad5556416b5",
      "5ee3ee26ffdf4e0aa64eb3a5635fa93e",
      "621da7d262b04cf7a59ced403761c535",
      "73eb51bb1a8746829483a61b74857b45",
      "3b872c03d104463ea7430c02b3afc667",
      "cad4fbc43a3f454ea4694636716872d9",
      "39c85da80f654bcb8992200f8eb320f1",
      "31e7d022779e4b5a8d018f5671b5353a",
      "f2098347385549f2a5e810deabb6a3a1"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T20:06:35.017250Z",
     "iopub.status.busy": "2025-03-15T20:06:35.015982Z",
     "iopub.status.idle": "2025-03-15T20:06:41.571463Z",
     "shell.execute_reply": "2025-03-15T20:06:41.570149Z",
     "shell.execute_reply.started": "2025-03-15T20:06:35.017194Z"
    },
    "id": "_QgpwFYiK991",
    "outputId": "260d658a-3c84-409b-d694-54b26075ba80",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15056/15056 [00:06<00:00, 2350.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average token len per sample: 69.67\n",
      "Minimum and maximum lens are: 4 and 3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞–µ–º –Ω–µ–º–Ω–æ–≥–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏, –æ–ø—Ä–µ–¥–µ–ª–∏–º—Å—è —Å —Ä–∞–∑–º–µ—Ä–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —É –º–æ–¥–µ–ª–∏\n",
    "\n",
    "lens = []\n",
    "for text in tqdm(dataset[\"test\"][\"text\"]):\n",
    "    ids = tokenizer.encode(text)\n",
    "    lens.append(len(ids))\n",
    "\n",
    "print(f\"Average token len per sample: {sum(lens) / len(lens):.2f}\")\n",
    "print(f\"Minimum and maximum lens are: {min(lens)} and {max(lens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwN3mfmznPW5"
   },
   "source": [
    "–î–æ–ª–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å—Å—è –≤ —Å—Ä–µ–¥–Ω–µ–º –ø–æ 70 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å.\n",
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ 128 —Ç–æ–∫–µ–Ω–æ–≤ –±—É–¥–µ—Ç –≤–ø–æ–ª–Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub1FljGXC7I-"
   },
   "source": [
    "# –ú–æ–¥–µ–ª—å [10 –±–∞–ª–ª–æ–≤]\n",
    "\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏ —Ä–µ–∞–ª–∏–∑—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä, –≤ –∫–æ—Ç–æ—Ä–æ–º\n",
    "1. –í –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ALiBi\n",
    "2. –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GQA\n",
    "3. –í Feed-Forward –±–ª–æ–∫–µ SwiGLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:08:19.948670Z",
     "iopub.status.busy": "2025-03-15T18:08:19.947243Z",
     "iopub.status.idle": "2025-03-15T18:08:19.965162Z",
     "shell.execute_reply": "2025-03-15T18:08:19.963940Z",
     "shell.execute_reply.started": "2025-03-15T18:08:19.948626Z"
    },
    "id": "ipZrCvkmK992",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∑–∞–≤–µ–¥–µ–º –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_kv_head: int\n",
    "    hidden_dim: int\n",
    "    intermediate_dim: int\n",
    "    dropout: float = 0.1\n",
    "    vocab_size: int = 1024\n",
    "    max_seq_len: int = 128\n",
    "\n",
    "\n",
    "model_configs = {\n",
    "    \"nano\": TransformerConfig(n_layer=3, n_head=4, n_kv_head=2, hidden_dim=96, intermediate_dim=256),\n",
    "    \"mini\": TransformerConfig(n_layer=6, n_head=6, n_kv_head=3, hidden_dim=384, intermediate_dim=1024),\n",
    "    \"small\": TransformerConfig(n_layer=12, n_head=12, n_kv_head=6, hidden_dim=768, intermediate_dim=2048),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "execution": {
     "iopub.execute_input": "2025-03-15T20:03:58.573888Z",
     "iopub.status.busy": "2025-03-15T20:03:58.572403Z",
     "iopub.status.idle": "2025-03-15T20:03:58.625157Z",
     "shell.execute_reply": "2025-03-15T20:03:58.623771Z",
     "shell.execute_reply.started": "2025-03-15T20:03:58.573844Z"
    },
    "id": "aYXMb5PEDFkt",
    "outputId": "4088f195-49ff-4d73-8507-b3b0c6443c0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"Root Mean Square Layer Normalization\n",
    "\n",
    "        Args:\n",
    "            dim: Feature dimension\n",
    "            eps: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        sum_dim = torch.sqrt((x * x).sum(-1) / x.shape[-1]+ self.eps).unsqueeze(-1)\n",
    "        scaled = (x / sum_dim) * self.scale.repeat(x.shape[0], 1, 1)\n",
    "        return scaled\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        \"\"\"Causal Self-Attention with support of\n",
    "        Grouped-Query Attention and ALiBi for positional encoding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        assert self.config.hidden_dim % self.config.n_head == 0\n",
    "        assert self.config.n_head % self.config.n_kv_head == 0\n",
    "        self.head_dim = self.config.hidden_dim // self.config.n_head\n",
    "        self.scale = self.head_dim**-0.5\n",
    "        self.q_per_kv = self.config.n_head // self.config.n_kv_head\n",
    "\n",
    "        # Init projection layers\n",
    "        self.q_proj = nn.Linear(self.config.hidden_dim, self.head_dim * self.config.n_head)\n",
    "        # –ø–æ—á–µ–º—É —Ç—É—Ç 1 —Å–ª–æ–π –Ω–∞ k –∏ v?\n",
    "        # self.q_proj = todo()\n",
    "        # self.kv_proj = todo()\n",
    "        # self.out_proj = todo()\n",
    "        self.k_proj = nn.Linear(self.config.hidden_dim, self.head_dim * self.config.n_kv_head)\n",
    "        self.v_proj = nn.Linear(self.config.hidden_dim, self.head_dim * self.config.n_kv_head)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        #self.out_proj = \n",
    "        self.register_buffer(\"causal_mask\", self._create_causal_mask(self.config.max_seq_len))\n",
    "        self.register_buffer(\"alibi\", self._build_alibi_bias(self.config.n_head))\n",
    "\n",
    "    def _build_alibi_bias(self, num_heads: int) -> Tensor:\n",
    "        \"\"\"Build ALiBi for specified number of heads:\n",
    "\n",
    "        Returns:\n",
    "            Tensor with ALiBi biases, shape: [1, num heads, 1, 1]\n",
    "        \"\"\"\n",
    "        step = 8 / num_heads \n",
    "        arange = [(1/2)**n for n in torch.arange(step, 8 + step, step)]\n",
    "        alibi = torch.tensor(arange).view(1, num_heads, 1, 1)\n",
    "        return alibi\n",
    "\n",
    "    def _create_causal_mask(self, max_seq_len: int) -> Tensor:\n",
    "        \"\"\"Create causal mask with ones where tokens can attend to each other.\n",
    "\n",
    "        Returns:\n",
    "            Tensor with causal mask, shape: [1, 1, seq len, seq len]\n",
    "        \"\"\"\n",
    "        mask = [[0 if j > i else 1 for j in range(max_seq_len)] for i in range(max_seq_len)]\n",
    "        return torch.tensor(mask).view(1, 1, max_seq_len, max_seq_len)\n",
    "\n",
    "    def forward(self, x: Tensor, attention_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"Apply Self-Attention to input data with respect to pad tokens.\n",
    "\n",
    "        Args:\n",
    "            x: input tensor, shape [bs, seq len, hidden dim]\n",
    "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len]\n",
    "        Returns:\n",
    "            result tensor, shape [bs, seq len, hidden dim]\n",
    "        \"\"\"\n",
    "        b_s = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        # –ü—Ä–∏–º–µ–Ω–∏–º —Å–ª–æ–∏ –ª–∏–Ω–µ–π–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞\n",
    "        q = rearrange(self.q_proj(x), \"b_s seq_len (h g head_dim) -> b_s g h seq_len head_dim\", head_dim=self.head_dim, h=self.config.n_kv_head) \n",
    "        k = rearrange(self.k_proj(x), \"b_s seq_len (h head_dim) -> b_s h seq_len head_dim\", head_dim=self.head_dim)\n",
    "        v = rearrange(self.v_proj(x), \"b_s seq_len (h head_dim) -> b_s h seq_len head_dim\", head_dim=self.head_dim)\n",
    "        # –ö–∞–∫ –∏—Ç–æ–≥ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ \n",
    "        # q - (b_s, g, h, seq_len, head_dim)\n",
    "        # v - (b_s, h, seq_len, head_dim)\n",
    "        # k - (b_s, h, seq_len, head_dim)\n",
    "        # print(q.shape, k.shape, v.shape)\n",
    "        # g - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä—É–ø–ø, h - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ–≤ V, K, head_dim - —Ä–∞–∑–º–µ—Ä –≥–æ–ª–æ–≤—ã, b_s - batch_size\n",
    "        relevance = einsum(q, k, \"b_s g h seq_len head_dim, b_s h seq_len_1 head_dim -> b_s g h seq_len seq_len_1\")\n",
    "        relevance = rearrange(relevance, \"b_s g h seq_len seq_len_1 -> b_s (g h) seq_len seq_len_1\")\n",
    "        \n",
    "        # –î–æ–±–∞–≤–∏–º alibi\n",
    "        diff_matrix = [[[j - i if j< i else 0 for j in range(seq_len)] for i in range(seq_len)] for b in range(b_s)]\n",
    "        bias = torch.tensor(diff_matrix, device='cuda' if torch.cuda.is_available() else 'cpu').view(b_s, 1, seq_len, seq_len).repeat(1, self.config.n_head, 1, 1)\n",
    "        ALiBi = self.alibi * bias\n",
    "        \n",
    "        relevance = relevance + ALiBi\n",
    "        # –Ω–∏–≥–¥–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é casual_mask –ø–æ–∫–∞ —á—Ç–æ\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.to(torch.bool)\n",
    "            attention_mask = rearrange(attention_mask, \"b_s seq_len-> b_s () () seq_len\")\n",
    "            \n",
    "            relevance = relevance.masked_fill_(~attention_mask, torch.finfo(relevance.dtype).min)\n",
    "        relevance = torch.softmax(relevance, dim=-1)\n",
    "        \n",
    "        relevance = self.attn_dropout(relevance)\n",
    "        relevance = rearrange(relevance, \"b_s (g h) seq_len seq_len_1 -> b_s g h seq_len seq_len_1\",h=self.config.n_kv_head)\n",
    "        values = einsum(relevance, v, \"b_s g h seq_len seq_len_1, b_s h seq_len head_dim -> b_s g h seq_len head_dim\")\n",
    "        values = rearrange(values, \" b_s g h seq_len head_dim -> b_s seq_len (g h head_dim)\")\n",
    "        return values\n",
    "    \n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        \"\"\"Gated Liner Unit with Swish Activation\"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Init up- and down- projection layers\n",
    "        self.fc_up1 = nn.Linear(self.config.hidden_dim, self.config.intermediate_dim)\n",
    "        self.fc_up2 = nn.Linear(self.config.hidden_dim, self.config.intermediate_dim)\n",
    "        self.fc_down = nn.Linear(self.config.intermediate_dim, self.config.hidden_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Apply SwiGLU to input data.\n",
    "\n",
    "        Args:\n",
    "            x: input tensor, shape [bs, seq len, hidden dim]\n",
    "        Returns:\n",
    "            result tensor, shape [bs, seq len, hidden dim]\n",
    "        \"\"\"\n",
    "        \n",
    "        up_1 = torch.sigmoid(self.fc_up1(x))\n",
    "        up_2 = self.fc_up2(x)\n",
    "        silu = nn.SiLU()\n",
    "        up_2 = silu(up_2)\n",
    "        multi = up_1 * up_2\n",
    "        \n",
    "        return self.fc_down(multi)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        \"\"\"Base Transformer Block\n",
    "        - Causal Self-Attention and SwiGLU as main elements\n",
    "        - Pre-normalization via RMSNorm\n",
    "        - Regularization with dropouts before residuals\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.ln_1 = RMSNorm(config.hidden_dim)\n",
    "        self.res_dropout_1 = nn.Dropout(config.dropout)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "\n",
    "        self.ln_2 = RMSNorm(config.hidden_dim)\n",
    "        self.res_dropout_2 = nn.Dropout(config.dropout)\n",
    "        self.mlp = SwiGLU(config)\n",
    "\n",
    "    def forward(self, x: Tensor, attention_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"Apply Transformer Block to input data.\n",
    "\n",
    "        Args:\n",
    "            x: input tensor, shape [bs, seq len, hidden dim]\n",
    "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
    "        Returns:\n",
    "            result tensor, shape [bs, seq len, hidden dim]\n",
    "        \"\"\"\n",
    "        norm_1 = self.ln_1(x)\n",
    "        drop_1 = self.res_dropout_1(norm_1)\n",
    "        attn = self.attn(drop_1, attention_mask)\n",
    "        \n",
    "        norm_2 = self.ln_2(attn)\n",
    "        drop_2 = self.res_dropout_2(norm_2)\n",
    "        attn_full = self.mlp(drop_2)\n",
    "        \n",
    "        return attn_full\n",
    "\n",
    "class TransformerForCausalLM(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        \"\"\"Transformer model for Language Modeling\"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.max_seq_len = config.max_seq_len\n",
    "        self.n_layer = config.n_layer\n",
    "        self.n_head = config.n_head\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        self.token_emb = nn.Embedding(self.vocab_size, self.hidden_dim)\n",
    "        self.emb_dropout = nn.Dropout(config.dropout)\n",
    "        self.layers = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
    "        self.ln_final = RMSNorm(config.hidden_dim)\n",
    "        self.lm_head = nn.Linear(self.hidden_dim, self.vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Number of parameters: {n_params / 1e6:.2f}M\")\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, RMSNorm):\n",
    "            torch.nn.init.ones_(module.scale)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor = None) -> Tensor:\n",
    "        \"\"\"Calculate logits for given input ids.\n",
    "\n",
    "        Args:\n",
    "            x: input tensor, shape [bs, seq len]\n",
    "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
    "        Returns:\n",
    "            logits, shape [bs, seq len, vocab_size]\n",
    "        \"\"\"\n",
    "        embeds = self.token_emb(input_ids)\n",
    "        embeds = self.emb_dropout(embeds)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            embeds = layer(embeds, attention_mask)\n",
    "        \n",
    "        embeds_drop = self.ln_final(embeds)\n",
    "        return self.lm_head(embeds_drop)\n",
    "        \n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(\n",
    "        self, idx: Tensor, max_new_tokens, eos_token_id, temperature=1.0, do_sample=False, top_k=None\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Take a conditioning sequence of indices and complete the sequence max_new_tokens times,\n",
    "        feeding the predictions back into the model each time.\n",
    "\n",
    "        Args:\n",
    "            idx: tensor with conditional tokens, shape [seq len]\n",
    "            max_new_tokens: maximum number of new tokens\n",
    "            eos_token_id: index of EOS token to stop generation\n",
    "            temperature, do_sample, top_k: generation parameters\n",
    "        Return:\n",
    "            tensor with generated indexes\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.shape[1] <= self.max_seq_len else idx[:, -self.max_seq_len :]\n",
    "            logits = self(idx_cond)\n",
    "            # 1. Pluck the logits at the final step and scale by desired temperature\n",
    "            logits = (logits[0][-1])**(1/temperature)\n",
    "            # 2. Optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                top = [i.item() for i in torch.topk(logits, top_k).indices]\n",
    "                mask = list(set(range(len(logits))) - set(top))\n",
    "                logits[mask] = -float(\"inf\")\n",
    "            # 3. apply softmax to convert logits to probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            #print(torch.sum(probs), 'probs')\n",
    "            #print(torch.isnan(prods).sum())\n",
    "            # 4. Either sample from the distribution or take the most likely element\n",
    "            if do_sample:\n",
    "                idx_next = torch.tensor(np.random.choice(range(self.vocab_size), p=np.nan_to_num(probs.cpu().numpy())), device='cuda' if torch.cuda.is_available()\n",
    "                                       else 'cpu')\n",
    "            else:\n",
    "                idx_next = torch.argmax(probs)\n",
    "            # print(idx_next.reshape(1, 1), idx)\n",
    "            idx_next = idx_next.reshape(1, 1)\n",
    "            \n",
    "            # 5. Append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "            if idx_next == eos_token_id:\n",
    "                break\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhdavMmSDujw"
   },
   "source": [
    "# Train Loop [2 + 2 –±–∞–ª–ª–∞]\n",
    "\n",
    "–ù–∞—Å—Ç–∞–ª–æ –≤—Ä–µ–º—è –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å.\n",
    "–ù–µ–±–æ–ª—å—à—É—é –º–æ–∂–Ω–æ –ø—Ä–æ–±–æ–≤–∞—Ç—å –æ–±—É—á–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–æ –ª—É—á—à–µ –≤—Å–µ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è GPU, –Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞ Google Colab.\n",
    "\n",
    "–ó–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é 2 –±–∞–ª–ª–∞, –∏ –µ—â–µ 2 –±–∞–ª–ª–∞ - –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–∞—É—á–∏–ª–∞—Å—å –≥–µ–Ω–µ—Ä–∏—Ç—å –∞–Ω–µ–∫–¥–æ—Ç—ã.\n",
    "\n",
    "–ù–µ –∑–∞–±—É–¥—å—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –Ω—É–∂–Ω—ã–µ –≤–µ—Å–∞ –Ω–∞ HF –∏ —É –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–≥–æ —Å–∫–∞—á–∞–µ—Ç—Å—è –Ω—É–∂–Ω–∞—è –≤–µ—Ä—Å–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T20:00:00.029840Z",
     "iopub.status.busy": "2025-03-15T20:00:00.028387Z",
     "iopub.status.idle": "2025-03-15T20:00:00.354449Z",
     "shell.execute_reply": "2025-03-15T20:00:00.352813Z",
     "shell.execute_reply.started": "2025-03-15T20:00:00.029786Z"
    },
    "id": "1wtAiR_aDxed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #0\n",
      "tensor([[1007,  589,   33, 1023, 1023, 1023, 1023, 1023, 1023, 1023, 1023, 1023,\n",
      "         1023, 1023],\n",
      "        [ 373,  339,  940,  260,  682,   63, 1023, 1023, 1023, 1023, 1023, 1023,\n",
      "         1023, 1023],\n",
      "        [ 375,  410,  676,  395,  264,  262,  323,  312,  269,  531,  365,  744,\n",
      "          526, 1023]])\n",
      "\n",
      "torch.Size([3, 14])\n"
     ]
    }
   ],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –∫–∞–∫ –∑–∞–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å —Å–µ–º–ø–ª—ã –≤ –±–∞—Ç—á\n",
    "# –†–∞–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É, –ø–æ—ç—Ç–æ–º—É –±—É–¥–µ—Ç –ø–∞–¥–∏—Ç—å –¥–æ —Å–∞–º–æ–≥–æ –¥–ª–∏–Ω–∞ —Å–µ–º–ø–ª–∞\n",
    "# –¢–∞–∫ –∂–µ –∑–∞–≤–µ–¥–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –º–∞—Å–∫—É, —á—Ç–æ–±—ã –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –Ω–µ —É—á–∏—Ç—ã–≤–∞–ª –ø–∞–¥–∏–Ω–≥–∏\n",
    "\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        texts = self.texts[idx]\n",
    "        tokenized_sequence = self.tokenizer.encode(texts)\n",
    "        return tokenized_sequence\n",
    "\n",
    "\n",
    "def data_collator(\n",
    "    tokenized_sequences: list[list[int]], pad_token_id: int, max_seq_len: int = None\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    batch_size = len(tokenized_sequences)\n",
    "    max_batch_seq_len = min(max_seq_len, max((len(it) for it in tokenized_sequences)))\n",
    "\n",
    "    input_ids = torch.full((batch_size, max_batch_seq_len), pad_token_id)\n",
    "    attention_mask = torch.zeros((batch_size, max_batch_seq_len))\n",
    "\n",
    "    for i, tok_seq in enumerate(tokenized_sequences):\n",
    "        cur_len = min(len(tok_seq), max_batch_seq_len)\n",
    "        input_ids[i, :cur_len] = torch.tensor(tok_seq[:cur_len])\n",
    "        attention_mask[i, :cur_len] = 1\n",
    "\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, pad_token_id, max_seq_len, batch_size, is_train):\n",
    "    collate_fn = partial(data_collator, pad_token_id=pad_token_id, max_seq_len=max_seq_len)\n",
    "    return DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=is_train, drop_last=is_train, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "\n",
    "\n",
    "_d = TextDataset([\"–ü—Ä–∏–≤–µ—Ç!\", \"–ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?\", \"–û—Å—Ç–∞–ª–æ—Å—å —Å–æ–≤—Å–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–æ –∫–æ–Ω—Ü–∞\"], tokenizer)\n",
    "_dl = create_dataloader(_d, tokenizer.eos_token_id, max_seq_len=16, batch_size=3, is_train=False)\n",
    "\n",
    "for i, batch in enumerate(_dl):\n",
    "    print(f\"Batch #{i}\")\n",
    "    input_ids, attn_mask = batch\n",
    "    print(input_ids, attn_mask.shape, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:11:57.979169Z",
     "iopub.status.busy": "2025-03-15T18:11:57.977820Z",
     "iopub.status.idle": "2025-03-15T18:11:58.029845Z",
     "shell.execute_reply": "2025-03-15T18:11:58.028425Z",
     "shell.execute_reply.started": "2025-03-15T18:11:57.979116Z"
    },
    "id": "i719AOdQK993",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
    "    \"\"\"Scheduler for Optimizer with linear warmup and linear decay to the end of training\n",
    "\n",
    "    Args:\n",
    "        optimizer: torch optimizer to control learning rate\n",
    "        num_warmup_steps: number of warmup steps\n",
    "        num_training_steps: total number of training steps\n",
    "    Return:\n",
    "        torch learning rate scheduler\n",
    "    \"\"\"\n",
    "    assert num_training_steps >= num_warmup_steps\n",
    "    max_lr = 0.1\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        min_lr = 0\n",
    "        start_lr = 0.01\n",
    "        max_lr = 0.1\n",
    "        step_down = (max_lr - min_lr) / (num_training_steps - num_warmup_steps)\n",
    "        step_up = (max_lr - start_lr) / num_warmup_steps\n",
    "        if current_step <= num_warmup_steps:\n",
    "            return start_lr + current_step * step_up\n",
    "        else:\n",
    "            return max_lr * 2 / 3- (current_step - num_warmup_steps) * step_down\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(input_ids: Tensor, attention_mask: Tensor, logits: Tensor) -> Tensor:\n",
    "    \"\"\"Calculate Cross-Entropy loss for Language Modeling task\n",
    "    Under the hood:\n",
    "    1. Create targtes based on input ids\n",
    "    2. Masked out tokens corresponded to paddings\n",
    "    3. Calculate cross entropy loss\n",
    "\n",
    "    Args:\n",
    "        input_ids: tensor with input ids, shape [bs, seq len]\n",
    "        attention_mask: mask with zeros for pad tokens, shape [bs, seq len]\n",
    "        logits: predicted logits, shape [bs, seq len, vocab size]\n",
    "    Return:\n",
    "        cross entropy loss, single-item tensor\n",
    "    \"\"\"\n",
    "    loss = nn.CrossEntropyLoss(ignore_index=tokenizer.eos_token_id)\n",
    "    targets = input_ids[:, 1:]\n",
    "    return loss(logits[:, :-1, :].transpose(1, 2), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:11:59.003292Z",
     "iopub.status.busy": "2025-03-15T18:11:59.002011Z",
     "iopub.status.idle": "2025-03-15T18:11:59.024632Z",
     "shell.execute_reply": "2025-03-15T18:11:59.023345Z",
     "shell.execute_reply.started": "2025-03-15T18:11:59.003235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# wandb.login(key='03473c2b8e9b6a50995c56a4492a3bcd7da7483f')\n",
    "\n",
    "# wandb.init(project=\"vk_hw1\", name=\"second_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:11:59.212228Z",
     "iopub.status.busy": "2025-03-15T18:11:59.210837Z",
     "iopub.status.idle": "2025-03-15T18:11:59.236160Z",
     "shell.execute_reply": "2025-03-15T18:11:59.234994Z",
     "shell.execute_reply.started": "2025-03-15T18:11:59.212171Z"
    },
    "id": "SPYdF52zXtoX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç—Ä–µ–Ω–µ—Ä–∞ —Å –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=3e-4,\n",
    "        weight_decay=0.01,\n",
    "        clip_grad_norm=1.0,\n",
    "        n_steps=10_000,\n",
    "        val_every_n_steps=1_000,\n",
    "        plot_every_n_steps=100,\n",
    "    ):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.clip_grad_norm = clip_grad_norm\n",
    "        self.n_steps = n_steps\n",
    "        self.val_every_n_steps = val_every_n_steps\n",
    "        self.plot_every_n_steps = plot_every_n_steps\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = \"mps\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        print(\"running on device\", self.device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, model, val_loader):\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
    "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)  # [bs; seq len; vocab size]\n",
    "            val_loss += cross_entropy_loss(input_ids, attention_mask, logits)\n",
    "        return val_loss / len(val_loader)\n",
    "\n",
    "    def run(self, model, train_loader, val_loader):\n",
    "        model = model.to(self.device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=0.1 * self.n_steps, num_training_steps=self.n_steps\n",
    "        )\n",
    "        model.train()\n",
    "        # wandb.watch(model, log='all', criterion=torch.nn.CrossEntropyLoss, log_freq=100)\n",
    "        plotlosses = PlotLosses(figsize=(15, 9), step_names=\"Step\")\n",
    "        logs = {\"lr\": 0, \"epoch\": 0}\n",
    "\n",
    "        data_iter = iter(train_loader)\n",
    "        for iter_num in range(self.n_steps):\n",
    "            try:\n",
    "                batch = next(data_iter)\n",
    "            except StopIteration:\n",
    "                data_iter = iter(train_loader)\n",
    "                logs[\"epoch\"] += 1\n",
    "                batch = next(data_iter)\n",
    "\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
    "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)  # [bs; seq len; vocab size]\n",
    "            loss = cross_entropy_loss(input_ids, attention_mask, logits)\n",
    "            \n",
    "            # backprop and update the parameters\n",
    "            model.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), self.clip_grad_norm)\n",
    "            # for param in model.parameters():\n",
    "            #     print('------------------------------------------------')\n",
    "            #     print(param.sum().item(), '—Å—É–º–º–º–∞ witghs\\n', \n",
    "            #           param.grad.sum(), '—Å—É–º–º–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\\n', \n",
    "            #           torch.isnan(param.grad).sum(), '—Å—É–º–º–∞ –Ω—É–ª–æ–≤\\n',\n",
    "            #           torch.isclose(param.grad, torch.zeros(param.grad.shape, device='cuda')).sum(), '—Ä–∞–≤–Ω—ã–µ –Ω—É–ª—é –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\\n')\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if iter_num > 0 and iter_num % self.val_every_n_steps == 0:\n",
    "                val_loss = self.validate(model, val_loader)\n",
    "                plotlosses.update({\"val_loss\": val_loss.item()}, current_step=iter_num)\n",
    "                plotlosses.send()\n",
    "                model.train()\n",
    "\n",
    "            if iter_num % self.plot_every_n_steps == 0:\n",
    "                logs[\"loss\"] = loss.item()\n",
    "                logs[\"lr\"] = scheduler.get_last_lr()[0]\n",
    "                plotlosses.update(logs, current_step=iter_num)\n",
    "                plotlosses.send()\n",
    "\n",
    "        val_loss = self.validate(model, val_loader)\n",
    "        plotlosses.update({\"val_loss\": val_loss.item()}, current_step=iter_num)\n",
    "        plotlosses.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:12:00.007667Z",
     "iopub.status.busy": "2025-03-15T18:12:00.006142Z",
     "iopub.status.idle": "2025-03-15T18:12:01.764222Z",
     "shell.execute_reply": "2025-03-15T18:12:01.762615Z",
     "shell.execute_reply.started": "2025-03-15T18:12:00.007613Z"
    },
    "id": "yK1BpJflMTAi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã\n",
    "\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = TextDataset(dataset[\"train\"][\"text\"], tokenizer)\n",
    "train_dataloader = create_dataloader(\n",
    "    train_dataset, tokenizer.eos_token_id, max_seq_len=MAX_SEQ_LEN, batch_size=BATCH_SIZE, is_train=True\n",
    ")\n",
    "\n",
    "test_dataset = TextDataset(dataset[\"test\"][\"text\"], tokenizer)\n",
    "test_dataloader = create_dataloader(\n",
    "    test_dataset, tokenizer.eos_token_id, max_seq_len=MAX_SEQ_LEN, batch_size=BATCH_SIZE, is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:12:01.766902Z",
     "iopub.status.busy": "2025-03-15T18:12:01.765780Z",
     "iopub.status.idle": "2025-03-15T18:12:02.002096Z",
     "shell.execute_reply": "2025-03-15T18:12:02.000848Z",
     "shell.execute_reply.started": "2025-03-15T18:12:01.766865Z"
    },
    "id": "53jHSgMZECGl",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 9.66M\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "\n",
    "config = model_configs[\"mini\"]\n",
    "model = TransformerForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:12:03.095658Z",
     "iopub.status.busy": "2025-03-15T18:12:03.094152Z",
     "iopub.status.idle": "2025-03-15T18:12:03.134846Z",
     "shell.execute_reply": "2025-03-15T18:12:03.133660Z",
     "shell.execute_reply.started": "2025-03-15T18:12:03.095619Z"
    },
    "id": "uMUsjHl4Nkoa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–µ—Ä–∞\n",
    "\n",
    "trainer = Trainer(learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nUgUfpKK993",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ goes brrrr!\n",
    "trainer.run(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "\n",
    "config = model_configs[\"mini\"]\n",
    "model = TransformerForCausalLM(config).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.from_pretrained(REPO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94zNDLEqdQow",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –°–º–æ—Ç—Ä–∏–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–ª–∞–∑–∞–º–∏\n",
    "# –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –∏ —Å–ª–∞–±—ã—Ö –º–æ–¥–µ–ª–µ–π \"–∑–∞—Ç—è–≥–∏–≤–∞–µ–º\" –≥–∞–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "\n",
    "text = \"–ó–∞—Ö–æ–¥–∏—Ç –≤ –±–∞—Ä\"\n",
    "input_ids = torch.tensor(tokenizer.encode(text)[:-1], device=trainer.device)[None, :]\n",
    "print(input_ids)\n",
    "model_output = model.generate(\n",
    "    input_ids, max_new_tokens=200, eos_token_id=tokenizer.eos_token_id, do_sample=True, top_k=10\n",
    ")\n",
    "tokenizer.decode(model_output[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T20:07:23.572657Z",
     "iopub.status.busy": "2025-03-15T20:07:23.571355Z",
     "iopub.status.idle": "2025-03-15T20:07:23.583727Z",
     "shell.execute_reply": "2025-03-15T20:07:23.582606Z",
     "shell.execute_reply.started": "2025-03-15T20:07:23.572599Z"
    },
    "id": "YFi7M9ExHWv9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±\n",
    "\n",
    "# model.push_to_hub(REPO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T20:07:23.607715Z",
     "iopub.status.busy": "2025-03-15T20:07:23.606510Z",
     "iopub.status.idle": "2025-03-15T20:07:23.619122Z",
     "shell.execute_reply": "2025-03-15T20:07:23.618029Z",
     "shell.execute_reply.started": "2025-03-15T20:07:23.607657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T20:07:25.295109Z",
     "iopub.status.busy": "2025-03-15T20:07:25.293852Z",
     "iopub.status.idle": "2025-03-15T20:07:25.310Z",
     "shell.execute_reply": "2025-03-15T20:07:25.308935Z",
     "shell.execute_reply.started": "2025-03-15T20:07:25.295067Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.push_to_hub(REPO_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WrMwV9zK993"
   },
   "source": [
    "–ü–æ–∏–≥—Ä–∞–π—Ç–µ—Å—å —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å `mini` –∏ `small` –≤–µ—Ä—Å–∏–∏.\n",
    "–ü–æ—Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å –¥–æ–±–∏—Ç—å—Å—è –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–∫ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö –ª–æ—Å—Å–∞, —Ç–∞–∫ –∏ –ø—Ä–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n",
    "\n",
    "### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã\n",
    "\n",
    "–í—ã —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã:\n",
    "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Rotary Positional Embedding **[4 –±–∞–ª–ª–∞]**\n",
    "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Multi-Head Latent Attention **[2 –±–∞–ª–ª]**\n",
    "- –û—Ñ–æ—Ä–º–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ ü§ó: –∫–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–¥–∞–Ω–∏—è, —Ä–µ–ø–æ—Ä—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ **[2 –±–∞–ª–ª]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ù–ï –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–æ—Ä–º –º–æ–¥–µ–ª—å, –ø—Ä–æ—Å—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –≤—Ä–µ–º–µ–Ω–∏( \n",
    "### –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –∫–æ—Ç–æ—Ä—É—é –Ω–µ –º–æ–∂–µ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä. –ù–∞–∏–ª—É—á—à–∏–π –ª–æ—Å—Å, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–±–∏–ª - 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so8bIDy5dKXM"
   },
   "source": [
    "# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–≥–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZplshN5HtRb"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer.from_pretrained(REPO_NAME)\n",
    "check_model = TransformerForCausalLM.from_pretrained(REPO_NAME)\n",
    "check_model = check_model.to(device)\n",
    "check_model = check_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "araF_3noK994"
   },
   "outputs": [],
   "source": [
    "text = \"–®—Ç–∏—Ä–ª–∏—Ü –ø—Ä–∏—à–µ–ª –¥–æ–º–æ–π\"\n",
    "input_ids = torch.tensor(tokenizer.encode(text), device=device)\n",
    "model_output = check_model.generate(\n",
    "    input_ids[None, :], max_new_tokens=200, eos_token_id=tokenizer.eos_token_id, do_sample=True, top_k=10\n",
    ")\n",
    "tokenizer.decode(model_output[0].tolist())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019ec19c587a4e7994f85c8454fe613f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c72de7e16ef44818bb66330fc549ef5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5cb623ff47ac43449f52fc327ebac6cb",
      "value": "‚Äá1024/1024‚Äá[02:48&lt;00:00,‚Äá‚Äá2.10it/s]"
     }
    },
    "037240195ea648ea977cbeddb6802e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4263d7a2a60640868b212423ad19460a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_17cd05a39e2f424ab2ab1e1b99563ed0",
      "value": "Loading‚Äádata:‚Äá100%"
     }
    },
    "053e185c1b06448797d09b5e87e9639a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad00686d85046af8b16caef0031c463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b92761d040a74ade8ba4472cdad0d8c9",
      "max": 135497,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad9ab0253a824e45b373b5756b5062f0",
      "value": 135497
     }
    },
    "0cf300f7cab7420e86f57e862008c1f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bef2bdc77c9495485eba1b25b8c1ea7",
       "IPY_MODEL_f0543bf2eda2481dbb19fad5556416b5",
       "IPY_MODEL_5ee3ee26ffdf4e0aa64eb3a5635fa93e"
      ],
      "layout": "IPY_MODEL_621da7d262b04cf7a59ced403761c535"
     }
    },
    "0e47a520ae554b42b2f1915aae431567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f958e47bb7c4dc28dab57743021b06b",
      "max": 1024,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2488b690c3947e9908968970903afba",
      "value": 1024
     }
    },
    "14c8108aeb4948a6a4ba3550ea9d37bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9abe5664d2d419cbcecd38c715d9922",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6ae4774b8711429eb28df01f421cfb0c",
      "value": "README.md:‚Äá100%"
     }
    },
    "17cd05a39e2f424ab2ab1e1b99563ed0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f62151ca61c4a5c87eeb5bb9aaf81de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25a6a07d0c2042b49faa8e9b90e9b520": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f37e138d5a4415b995eb782821e852b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31e7d022779e4b5a8d018f5671b5353a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3337363073324d59930d930e2bb9a4ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8183376e49a1468695840a2c28e1c2e8",
      "max": 41714945,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f3ae8e54b88464085c79265f3f1cbe6",
      "value": 41714945
     }
    },
    "39c85da80f654bcb8992200f8eb320f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b872c03d104463ea7430c02b3afc667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d557e71f38243ebb6c85fb3e047e84e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f62151ca61c4a5c87eeb5bb9aaf81de",
      "max": 99,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_576096f3007944df9d4ff5af3d6c413d",
      "value": 99
     }
    },
    "4263d7a2a60640868b212423ad19460a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e8103f6f1d348348cb3d0ead13c08a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_037240195ea648ea977cbeddb6802e3c",
       "IPY_MODEL_0ad00686d85046af8b16caef0031c463",
       "IPY_MODEL_ed9c593acfca4464875afefb495b0504"
      ],
      "layout": "IPY_MODEL_7510595287c1413a95cbfade6c892a6b"
     }
    },
    "4f958e47bb7c4dc28dab57743021b06b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5430ae92129342f19d5fceed4f0e3eb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "576096f3007944df9d4ff5af3d6c413d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c9b1715d728425abe95eebc527b7176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cb623ff47ac43449f52fc327ebac6cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ee3ee26ffdf4e0aa64eb3a5635fa93e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31e7d022779e4b5a8d018f5671b5353a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f2098347385549f2a5e810deabb6a3a1",
      "value": "‚Äá15056/15056‚Äá[00:05&lt;00:00,‚Äá2697.64it/s]"
     }
    },
    "5f3ae8e54b88464085c79265f3f1cbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "621da7d262b04cf7a59ced403761c535": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ae4774b8711429eb28df01f421cfb0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73eb51bb1a8746829483a61b74857b45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7510595287c1413a95cbfade6c892a6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eea9472943a4a46aea249ac2d34add6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd13ac6e0154498390a04783992ca005",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2f37e138d5a4415b995eb782821e852b",
      "value": "dataset.txt:‚Äá100%"
     }
    },
    "8183376e49a1468695840a2c28e1c2e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89e4f0d4d779403a96da3b69fd541e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bef2bdc77c9495485eba1b25b8c1ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73eb51bb1a8746829483a61b74857b45",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3b872c03d104463ea7430c02b3afc667",
      "value": "100%"
     }
    },
    "8c72de7e16ef44818bb66330fc549ef5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ee13c0245bb4bbe9322eae6765e9cad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9283be55fa9748458f7beccfb709dd8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "956b26d084924d2582574db2be8d97c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f33ccba758e49d3a7c31c29d34701a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2488b690c3947e9908968970903afba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad9ab0253a824e45b373b5756b5062f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae91c80126594ce485b022d87bc6f9f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae9bed8b24c94d3688321ced271545d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae91c80126594ce485b022d87bc6f9f9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b0e15a7eb24b430fb6d42fc10b6c8ebe",
      "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
     }
    },
    "b0e15a7eb24b430fb6d42fc10b6c8ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b92761d040a74ade8ba4472cdad0d8c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb14a1a17c044c6d99331047b1072c55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae9bed8b24c94d3688321ced271545d3",
       "IPY_MODEL_f8b0945c30b04470b16227e9c470d135",
       "IPY_MODEL_f4e211125114450b8000ed793d25cf5f"
      ],
      "layout": "IPY_MODEL_053e185c1b06448797d09b5e87e9639a"
     }
    },
    "c86beee2cbbf4f949f9e02ababbe58ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0c6421149b641ef892e3c99d85b2727",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f2cf249ff0db4a70a67e6ef9ce37da02",
      "value": "Building‚Äávocabulary:‚Äá100%"
     }
    },
    "c9abe5664d2d419cbcecd38c715d9922": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca6256d7781343ffa87c7a727818b48b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7eea9472943a4a46aea249ac2d34add6",
       "IPY_MODEL_3337363073324d59930d930e2bb9a4ed",
       "IPY_MODEL_e211fd35db594830a66d0aeaf78eeb98"
      ],
      "layout": "IPY_MODEL_eca658866bac4dab9a92b5d18bd5a93b"
     }
    },
    "cad4fbc43a3f454ea4694636716872d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0c6421149b641ef892e3c99d85b2727": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2d3a80f70474cbdb516a373f06bf9a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d983d2e8ac7944a58434df7c4535b019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dce0fdb966f64c629c8e7ede50fe0207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c86beee2cbbf4f949f9e02ababbe58ff",
       "IPY_MODEL_0e47a520ae554b42b2f1915aae431567",
       "IPY_MODEL_019ec19c587a4e7994f85c8454fe613f"
      ],
      "layout": "IPY_MODEL_25a6a07d0c2042b49faa8e9b90e9b520"
     }
    },
    "e18aaaff13e34718a78e002f9885df74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14c8108aeb4948a6a4ba3550ea9d37bf",
       "IPY_MODEL_3d557e71f38243ebb6c85fb3e047e84e",
       "IPY_MODEL_fce9a87690fe4561a53b054c79e43d53"
      ],
      "layout": "IPY_MODEL_956b26d084924d2582574db2be8d97c0"
     }
    },
    "e211fd35db594830a66d0aeaf78eeb98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9283be55fa9748458f7beccfb709dd8e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8ee13c0245bb4bbe9322eae6765e9cad",
      "value": "‚Äá41.7M/41.7M‚Äá[00:00&lt;00:00,‚Äá74.7MB/s]"
     }
    },
    "eca658866bac4dab9a92b5d18bd5a93b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed9c593acfca4464875afefb495b0504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89e4f0d4d779403a96da3b69fd541e8c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d983d2e8ac7944a58434df7c4535b019",
      "value": "‚Äá135497/135497‚Äá[00:27&lt;00:00,‚Äá6983.86it/s]"
     }
    },
    "f0543bf2eda2481dbb19fad5556416b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cad4fbc43a3f454ea4694636716872d9",
      "max": 15056,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39c85da80f654bcb8992200f8eb320f1",
      "value": 15056
     }
    },
    "f2098347385549f2a5e810deabb6a3a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2cf249ff0db4a70a67e6ef9ce37da02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4e211125114450b8000ed793d25cf5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2d3a80f70474cbdb516a373f06bf9a3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fed46355edb84e45834d4d9906817770",
      "value": "‚Äá150553/150553‚Äá[00:01&lt;00:00,‚Äá124397.98‚Äáexamples/s]"
     }
    },
    "f8b0945c30b04470b16227e9c470d135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f93543a7b33a42339b37b9cbab78b330",
      "max": 150553,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5430ae92129342f19d5fceed4f0e3eb3",
      "value": 150553
     }
    },
    "f93543a7b33a42339b37b9cbab78b330": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fce9a87690fe4561a53b054c79e43d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c9b1715d728425abe95eebc527b7176",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9f33ccba758e49d3a7c31c29d34701a6",
      "value": "‚Äá99.0/99.0‚Äá[00:00&lt;00:00,‚Äá2.04kB/s]"
     }
    },
    "fd13ac6e0154498390a04783992ca005": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fed46355edb84e45834d4d9906817770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
